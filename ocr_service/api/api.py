import json
import sys
import logging
import uuid
import traceback
import base64

from typing import Optional

from ocr_service.processor.processor import Processor
from fastapi import APIRouter, Request, UploadFile, File
from fastapi.responses import JSONResponse, Response

from multiprocessing import Pool

from config import CPU_THREADS, TESSERACT_TIMEOUT, LOG_LEVEL, OCR_SERVICE_RESPONSE_OUTPUT_TYPE
from ocr_service.utils.utils import build_response, get_app_info, setup_logging

sys.path.append("..")


api = APIRouter(prefix="/api")
log = setup_logging("api", log_level=LOG_LEVEL)


@api.get("/info")
def info() -> JSONResponse:
    return JSONResponse(content=get_app_info())


@api.post("/process")
async def process(request: Request, file: Optional[UploadFile]) -> Response:
    """
     Processes raw binary input stream, file, or
        JSON containing the binary_data field in base64 format

    Returns:
        Response: json with the result of the OCR processing
    """

    footer = {}
    file_name: str = ""
    stream: bytes = b""

    global log

    if file:
        file_name: str = file.filename if file.filename else ""
        stream = await file.read()
        log.info(f"Processing file given via 'file' parameter, file name: {file_name}")
    else:
        file_name = uuid.uuid4().hex
        log.info(f"Processing binary as data-binary, generated file name: {file_name}")
        raw_body = await request.body()

        try:
            record = json.loads(raw_body)
            if isinstance(record, list) and len(record) > 0:
                record = record[0]

            if isinstance(record, dict) and "binary_data" in record:
                stream = base64.b64decode(record["binary_data"])
                footer = record.get("footer", {})
                log.info("Footer found in the request.")
            else:
                stream = raw_body

            log.info("Stream contains valid JSON.")
        except json.JSONDecodeError:
            stream = raw_body
            log.warning("Stream does not contain valid JSON.")

    processor: Processor = request.app.state.processor
    output_text, doc_metadata = processor.process_stream(stream=stream, file_name=file_name)  # type: ignore

    code = 200 if len(output_text) > 0 else 500

    response = build_response(output_text,
                              footer=footer,
                              metadata=doc_metadata)

    if OCR_SERVICE_RESPONSE_OUTPUT_TYPE == "json":
        response = json.dumps({"result": response})
    elif OCR_SERVICE_RESPONSE_OUTPUT_TYPE == "dict":
        response = json.dumps({"result": response}).encode("utf-8")

    return Response(content=response, status_code=code)


@api.post("/process_file")
async def process_file(request: Request, file: UploadFile = File(...)) -> Response:

    file_name: str = file.filename if file.filename else ""
    stream = await file.read()
    log.info(f"Processing file: {file_name}")

    processor: Processor = request.app.state.processor

    output_text, doc_metadata = processor.process_stream(stream=stream, file_name=file_name)

    code = 200 if len(output_text) > 0 else 500

    response = build_response(output_text,
                              metadata=doc_metadata)

    if OCR_SERVICE_RESPONSE_OUTPUT_TYPE == "json":
        response = json.dumps({"result": response})
    elif OCR_SERVICE_RESPONSE_OUTPUT_TYPE == "dict":
        response = json.dumps({"result": response}).encode("utf-8")

    return Response(content=response, status_code=code)


@api.post("/process_bulk")
async def process_bulk(request: Request) -> Response:
    """
        Processes multiple files in a single request.
    """

    form = await request.form()
    file_streams = {}

    proc_results = list()
    ocr_results = []

    processor: Processor = request.app.state.processor

    # collect uploaded files
    for name, file in form.items():
        if isinstance(file, UploadFile):
            content = await file.read()
            file_streams[file.filename] = content

    with Pool(processes=CPU_THREADS) as process_pool:
        count = 0

        for file_name, file_stream in file_streams.items():
            count += 1
            proc_results.append(process_pool.starmap_async(processor.process_stream,
                                                           [(file_name, file_stream)],
                                                           chunksize=1,
                                                           error_callback=logging.error))
        try:
            for result in proc_results:
                ocr_results.append(result.get(timeout=TESSERACT_TIMEOUT))
        except Exception:
            raise Exception("OCR exception generated by worker: " + str(traceback.format_exc()))

    return Response(content={"response": "Not yet implemented"}, status_code=200)
